{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Import this for the relu function\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = F.relu(self.e11(x))\n",
    "        xe12 = F.relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = F.relu(self.e21(xp1))\n",
    "        xe22 = F.relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = F.relu(self.e31(xp2))\n",
    "        xe32 = F.relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = F.relu(self.e41(xp3))\n",
    "        xe42 = F.relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = F.relu(self.e51(xp4))\n",
    "        xe52 = F.relu(self.e52(xe51))\n",
    "\n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = F.relu(self.d11(xu11))\n",
    "        xd12 = F.relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = F.relu(self.d21(xu22))\n",
    "        xd22 = F.relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = F.relu(self.d31(xu33))\n",
    "        xd32 = F.relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = F.relu(self.d41(xu44))\n",
    "        xd42 = F.relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.685497, dice: 0.990572, loss: 0.838035\n",
      "val: bce: 0.674462, dice: 0.990246, loss: 0.832354\n",
      "saving best model\n",
      "2m 2s\n",
      "Epoch 1/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.668284, dice: 0.990540, loss: 0.829412\n",
      "val: bce: 0.655759, dice: 0.990242, loss: 0.823001\n",
      "saving best model\n",
      "1m 60s\n",
      "Epoch 2/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.644974, dice: 0.990533, loss: 0.817754\n",
      "val: bce: 0.623436, dice: 0.990253, loss: 0.806844\n",
      "saving best model\n",
      "2m 1s\n",
      "Epoch 3/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.603726, dice: 0.990557, loss: 0.797142\n",
      "val: bce: 0.561696, dice: 0.990320, loss: 0.776008\n",
      "saving best model\n",
      "1m 59s\n",
      "Epoch 4/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.517221, dice: 0.990693, loss: 0.753957\n",
      "val: bce: 0.411241, dice: 0.990858, loss: 0.701050\n",
      "saving best model\n",
      "1m 60s\n",
      "Epoch 5/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.279259, dice: 0.992659, loss: 0.635959\n",
      "val: bce: 0.063730, dice: 0.997429, loss: 0.530580\n",
      "saving best model\n",
      "1m 48s\n",
      "Epoch 6/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.103550, dice: 0.995790, loss: 0.549670\n",
      "val: bce: 0.099449, dice: 0.995321, loss: 0.547385\n",
      "1m 20s\n",
      "Epoch 7/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.068152, dice: 0.995857, loss: 0.532005\n",
      "val: bce: 0.043830, dice: 0.995925, loss: 0.519877\n",
      "saving best model\n",
      "1m 20s\n",
      "Epoch 8/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.039128, dice: 0.994308, loss: 0.516718\n",
      "val: bce: 0.037891, dice: 0.990718, loss: 0.514305\n",
      "saving best model\n",
      "1m 24s\n",
      "Epoch 9/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.036566, dice: 0.988032, loss: 0.512299\n",
      "val: bce: 0.035639, dice: 0.984093, loss: 0.509866\n",
      "saving best model\n",
      "1m 28s\n",
      "Epoch 10/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.032946, dice: 0.981762, loss: 0.507354\n",
      "val: bce: 0.030534, dice: 0.977726, loss: 0.504130\n",
      "saving best model\n",
      "1m 26s\n",
      "Epoch 11/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.028529, dice: 0.973769, loss: 0.501149\n",
      "val: bce: 0.027282, dice: 0.965809, loss: 0.496546\n",
      "saving best model\n",
      "1m 28s\n",
      "Epoch 12/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.025681, dice: 0.958206, loss: 0.491943\n",
      "val: bce: 0.024612, dice: 0.943832, loss: 0.484222\n",
      "saving best model\n",
      "6m 4s\n",
      "Epoch 13/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.022929, dice: 0.930846, loss: 0.476887\n",
      "val: bce: 0.021605, dice: 0.905798, loss: 0.463702\n",
      "saving best model\n",
      "2m 32s\n",
      "Epoch 14/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.020157, dice: 0.889645, loss: 0.454901\n",
      "val: bce: 0.019442, dice: 0.863123, loss: 0.441282\n",
      "saving best model\n",
      "2m 25s\n",
      "Epoch 15/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.018526, dice: 0.852286, loss: 0.435406\n",
      "val: bce: 0.018587, dice: 0.830535, loss: 0.424561\n",
      "saving best model\n",
      "2m 40s\n",
      "Epoch 16/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.017990, dice: 0.822099, loss: 0.420045\n",
      "val: bce: 0.018442, dice: 0.804045, loss: 0.411244\n",
      "saving best model\n",
      "3m 7s\n",
      "Epoch 17/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.017945, dice: 0.798441, loss: 0.408193\n",
      "val: bce: 0.018221, dice: 0.783935, loss: 0.401078\n",
      "saving best model\n",
      "2m 14s\n",
      "Epoch 18/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.017623, dice: 0.780519, loss: 0.399071\n",
      "val: bce: 0.017937, dice: 0.769646, loss: 0.393791\n",
      "saving best model\n",
      "2m 12s\n",
      "Epoch 19/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.017520, dice: 0.768082, loss: 0.392801\n",
      "val: bce: 0.018246, dice: 0.758698, loss: 0.388472\n",
      "saving best model\n",
      "2m 12s\n",
      "Epoch 20/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.018021, dice: 0.755942, loss: 0.386982\n",
      "val: bce: 0.018285, dice: 0.747119, loss: 0.382702\n",
      "saving best model\n",
      "2m 23s\n",
      "Epoch 21/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.018197, dice: 0.743542, loss: 0.380869\n",
      "val: bce: 0.018980, dice: 0.733161, loss: 0.376070\n",
      "saving best model\n",
      "2m 1s\n",
      "Epoch 22/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.018723, dice: 0.730652, loss: 0.374688\n",
      "val: bce: 0.019666, dice: 0.714910, loss: 0.367288\n",
      "saving best model\n",
      "2m 3s\n",
      "Epoch 23/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.019324, dice: 0.712432, loss: 0.365878\n",
      "val: bce: 0.020321, dice: 0.694736, loss: 0.357528\n",
      "saving best model\n",
      "2m 2s\n",
      "Epoch 24/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.020219, dice: 0.689273, loss: 0.354746\n",
      "val: bce: 0.021099, dice: 0.669649, loss: 0.345374\n",
      "saving best model\n",
      "7m 32s\n",
      "Epoch 25/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.021928, dice: 0.661994, loss: 0.341961\n",
      "val: bce: 0.023725, dice: 0.639509, loss: 0.331617\n",
      "saving best model\n",
      "5m 58s\n",
      "Epoch 26/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.023261, dice: 0.635266, loss: 0.329264\n",
      "val: bce: 0.026725, dice: 0.624358, loss: 0.325542\n",
      "saving best model\n",
      "10m 46s\n",
      "Epoch 27/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.024603, dice: 0.620350, loss: 0.322477\n",
      "val: bce: 0.026919, dice: 0.608715, loss: 0.317817\n",
      "saving best model\n",
      "3m 46s\n",
      "Epoch 28/59\n",
      "----------\n",
      "LR 0.0001\n",
      "train: bce: 0.025274, dice: 0.602367, loss: 0.313821\n",
      "val: bce: 0.025428, dice: 0.589218, loss: 0.307323\n",
      "saving best model\n",
      "21m 48s\n",
      "Epoch 29/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.025132, dice: 0.589216, loss: 0.307174\n",
      "val: bce: 0.025553, dice: 0.587677, loss: 0.306615\n",
      "saving best model\n",
      "12m 34s\n",
      "Epoch 30/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.025215, dice: 0.586947, loss: 0.306081\n",
      "val: bce: 0.025649, dice: 0.586096, loss: 0.305872\n",
      "saving best model\n",
      "8m 35s\n",
      "Epoch 31/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.025316, dice: 0.585266, loss: 0.305291\n",
      "val: bce: 0.025746, dice: 0.584773, loss: 0.305260\n",
      "saving best model\n",
      "4m 30s\n",
      "Epoch 32/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.025364, dice: 0.583545, loss: 0.304455\n",
      "val: bce: 0.025693, dice: 0.583155, loss: 0.304424\n",
      "saving best model\n",
      "3m 1s\n",
      "Epoch 33/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.025137, dice: 0.582040, loss: 0.303589\n",
      "val: bce: 0.025269, dice: 0.582036, loss: 0.303652\n",
      "saving best model\n",
      "3m 11s\n",
      "Epoch 34/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024739, dice: 0.580897, loss: 0.302818\n",
      "val: bce: 0.024942, dice: 0.580983, loss: 0.302963\n",
      "saving best model\n",
      "3m 1s\n",
      "Epoch 35/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024663, dice: 0.579332, loss: 0.301998\n",
      "val: bce: 0.025117, dice: 0.579474, loss: 0.302295\n",
      "saving best model\n",
      "2m 43s\n",
      "Epoch 36/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024792, dice: 0.577519, loss: 0.301156\n",
      "val: bce: 0.025255, dice: 0.577926, loss: 0.301590\n",
      "saving best model\n",
      "2m 19s\n",
      "Epoch 37/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024884, dice: 0.575850, loss: 0.300367\n",
      "val: bce: 0.025154, dice: 0.576574, loss: 0.300864\n",
      "saving best model\n",
      "2m 11s\n",
      "Epoch 38/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024600, dice: 0.574514, loss: 0.299557\n",
      "val: bce: 0.024769, dice: 0.575600, loss: 0.300184\n",
      "saving best model\n",
      "2m 10s\n",
      "Epoch 39/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024389, dice: 0.573129, loss: 0.298759\n",
      "val: bce: 0.024770, dice: 0.574099, loss: 0.299435\n",
      "saving best model\n",
      "2m 11s\n",
      "Epoch 40/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024435, dice: 0.571500, loss: 0.297968\n",
      "val: bce: 0.024869, dice: 0.572670, loss: 0.298769\n",
      "saving best model\n",
      "2m 14s\n",
      "Epoch 41/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024523, dice: 0.569807, loss: 0.297165\n",
      "val: bce: 0.024833, dice: 0.571287, loss: 0.298060\n",
      "saving best model\n",
      "2m 8s\n",
      "Epoch 42/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024383, dice: 0.568345, loss: 0.296364\n",
      "val: bce: 0.024646, dice: 0.570057, loss: 0.297352\n",
      "saving best model\n",
      "2m 9s\n",
      "Epoch 43/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024128, dice: 0.567046, loss: 0.295587\n",
      "val: bce: 0.024395, dice: 0.568859, loss: 0.296627\n",
      "saving best model\n",
      "2m 9s\n",
      "Epoch 44/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024113, dice: 0.565516, loss: 0.294815\n",
      "val: bce: 0.024574, dice: 0.567237, loss: 0.295906\n",
      "saving best model\n",
      "2m 9s\n",
      "Epoch 45/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.024101, dice: 0.563919, loss: 0.294010\n",
      "val: bce: 0.024369, dice: 0.566196, loss: 0.295282\n",
      "saving best model\n",
      "2m 11s\n",
      "Epoch 46/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023957, dice: 0.562537, loss: 0.293247\n",
      "val: bce: 0.024351, dice: 0.564757, loss: 0.294554\n",
      "saving best model\n",
      "2m 10s\n",
      "Epoch 47/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023966, dice: 0.561020, loss: 0.292493\n",
      "val: bce: 0.024334, dice: 0.563377, loss: 0.293855\n",
      "saving best model\n",
      "2m 9s\n",
      "Epoch 48/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023795, dice: 0.559741, loss: 0.291768\n",
      "val: bce: 0.024029, dice: 0.562372, loss: 0.293200\n",
      "saving best model\n",
      "2m 42s\n",
      "Epoch 49/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023656, dice: 0.558295, loss: 0.290975\n",
      "val: bce: 0.024098, dice: 0.560855, loss: 0.292476\n",
      "saving best model\n",
      "6m 33s\n",
      "Epoch 50/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023648, dice: 0.556863, loss: 0.290255\n",
      "val: bce: 0.024023, dice: 0.559519, loss: 0.291771\n",
      "saving best model\n",
      "11m 8s\n",
      "Epoch 51/59\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.023631, dice: 0.555325, loss: 0.289478\n",
      "val: bce: 0.024026, dice: 0.558147, loss: 0.291086\n",
      "saving best model\n",
      "2m 6s\n",
      "Epoch 52/59\n",
      "----------\n",
      "LR 1e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Model import UNet  # Import your U-Net model from Model.py or Model.ipynb\n",
    "\n",
    "# Instantiate your U-Net model\n",
    "model = UNet(n_class=1)  # Adjust n_class according to your task (e.g., number of classes for segmentation)\n",
    "\n",
    "# Set your model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Assuming images_tensor is already loaded and preprocessed\n",
    "# It should be of shape (batch_size, channels, height, width)\n",
    "# Example: images_tensor.shape => torch.Size([batch_size, 3, 256, 256])\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    output = model(images_tensor)\n",
    "\n",
    "# 'output' will contain the predictions; you can further process or use this output as needed\n",
    "# Example: output.shape => torch.Size([batch_size, n_class, height, width])\n",
    "\n",
    "# Example: Save or visualize the output (adjust as per your requirement)\n",
    "# Assuming 'output' is in the format suitable for your task\n",
    "# Example: output.shape => torch.Size([batch_size, n_class, height, width])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
