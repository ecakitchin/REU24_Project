{"cells":[{"cell_type":"markdown","metadata":{"vscode":{"languageId":"plaintext"}},"source":["# Data Processing Notebook!"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","from functools import reduce\n","import itertools\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets, models\n","from collections import defaultdict\n","import torch.nn.functional as F\n","import torch\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import time\n","import copy\n","\n","\n","def generate_random_data(height, width, count):\n","    x, y = zip(*[generate_img_and_mask(height, width) for i in range(0, count)])\n","\n","    X = np.asarray(x) * 255\n","    X = X.repeat(3, axis=1).transpose([0, 2, 3, 1]).astype(np.uint8)\n","    Y = np.asarray(y)\n","\n","    return X, Y\n","\n","\n","def generate_img_and_mask(height, width):\n","    shape = (height, width)\n","\n","    triangle_location = get_random_location(*shape)\n","    circle_location1 = get_random_location(*shape, zoom=0.7)\n","    circle_location2 = get_random_location(*shape, zoom=0.5)\n","    mesh_location = get_random_location(*shape)\n","    square_location = get_random_location(*shape, zoom=0.8)\n","    plus_location = get_random_location(*shape, zoom=1.2)\n","\n","    # Create input image\n","    arr = np.zeros(shape, dtype=bool)\n","    arr = add_triangle(arr, *triangle_location)\n","    arr = add_circle(arr, *circle_location1)\n","    arr = add_circle(arr, *circle_location2, fill=True)\n","    arr = add_mesh_square(arr, *mesh_location)\n","    arr = add_filled_square(arr, *square_location)\n","    arr = add_plus(arr, *plus_location)\n","    arr = np.reshape(arr, (1, height, width)).astype(np.float32)\n","\n","    # Create target masks\n","    masks = np.asarray([\n","        add_filled_square(np.zeros(shape, dtype=bool), *square_location),\n","        add_circle(np.zeros(shape, dtype=bool), *circle_location2, fill=True),\n","        add_triangle(np.zeros(shape, dtype=bool), *triangle_location),\n","        add_circle(np.zeros(shape, dtype=bool), *circle_location1),\n","         add_filled_square(np.zeros(shape, dtype=bool), *mesh_location),\n","        # add_mesh_square(np.zeros(shape, dtype=bool), *mesh_location),\n","        add_plus(np.zeros(shape, dtype=bool), *plus_location)\n","    ]).astype(np.float32)\n","\n","    return arr, masks\n","\n","\n","def add_square(arr, x, y, size):\n","    s = int(size / 2)\n","    arr[x-s,y-s:y+s] = True\n","    arr[x+s,y-s:y+s] = True\n","    arr[x-s:x+s,y-s] = True\n","    arr[x-s:x+s,y+s] = True\n","\n","    return arr\n","\n","\n","def add_filled_square(arr, x, y, size):\n","    s = int(size / 2)\n","\n","    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n","\n","    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, yy > y - s, yy < y + s]))\n","\n","\n","def logical_and(arrays):\n","    new_array = np.ones(arrays[0].shape, dtype=bool)\n","    for a in arrays:\n","        new_array = np.logical_and(new_array, a)\n","\n","    return new_array\n","\n","\n","def add_mesh_square(arr, x, y, size):\n","    s = int(size / 2)\n","\n","    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n","\n","    return np.logical_or(arr, logical_and([xx > x - s, xx < x + s, xx % 2 == 1, yy > y - s, yy < y + s, yy % 2 == 1]))\n","\n","\n","def add_triangle(arr, x, y, size):\n","    s = int(size / 2)\n","\n","    triangle = np.tril(np.ones((size, size), dtype=bool))\n","\n","    arr[x-s:x-s+triangle.shape[0],y-s:y-s+triangle.shape[1]] = triangle\n","\n","    return arr\n","\n","\n","def add_circle(arr, x, y, size, fill=False):\n","    xx, yy = np.mgrid[:arr.shape[0], :arr.shape[1]]\n","    circle = np.sqrt((xx - x) ** 2 + (yy - y) ** 2)\n","    new_arr = np.logical_or(arr, np.logical_and(circle < size, circle >= size * 0.7 if not fill else True))\n","\n","    return new_arr\n","\n","\n","def add_plus(arr, x, y, size):\n","    s = int(size / 2)\n","    arr[x-1:x+1,y-s:y+s] = True\n","    arr[x-s:x+s,y-1:y+1] = True\n","\n","    return arr\n","\n","\n","def get_random_location(width, height, zoom=1.0):\n","    x = int(width * random.uniform(0.1, 0.9))\n","    y = int(height * random.uniform(0.1, 0.9))\n","\n","    size = int(min(width, height) * random.uniform(0.06, 0.12) * zoom)\n","\n","    return (x, y, size)\n","\n","\n","def plot_img_array(img_array, ncol=3):\n","    nrow = len(img_array) // ncol\n","\n","    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n","\n","    for i in range(len(img_array)):\n","        plots[i // ncol, i % ncol]\n","        plots[i // ncol, i % ncol].imshow(img_array[i])\n","\n","\n","def plot_side_by_side(img_arrays):\n","    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n","\n","    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))\n","\n","\n","def plot_errors(results_dict, title):\n","    markers = itertools.cycle(('+', 'x', 'o'))\n","\n","    plt.title('{}'.format(title))\n","\n","    for label, result in sorted(results_dict.items()):\n","        plt.plot(result, marker=next(markers), label=label)\n","        plt.ylabel('dice_coef')\n","        plt.xlabel('epoch')\n","        plt.legend(loc=3, bbox_to_anchor=(1, 0))\n","\n","    plt.show()\n","\n","\n","def masks_to_colorimg(masks):\n","    colors = np.asarray([(201, 58, 64), (242, 207, 1), (0, 152, 75), (101, 172, 228),(56, 34, 132), (160, 194, 56)])\n","\n","    colorimg = np.ones((masks.shape[1], masks.shape[2], 3), dtype=np.float32) * 255\n","    channels, height, width = masks.shape\n","\n","    for y in range(height):\n","        for x in range(width):\n","            selected_colors = colors[masks[:,y,x] > 0.5]\n","\n","            if len(selected_colors) > 0:\n","                colorimg[y,x,:] = np.mean(selected_colors, axis=0)\n","\n","    return colorimg.astype(np.uint8)\n","\n","\n","def generate_images_and_masks_then_plot():\n","    # Generate some random images\n","    input_images, target_masks = generate_random_data(192, 192, count=3)\n","\n","    for x in [input_images, target_masks]:\n","        print(x.shape)\n","        print(x.min(), x.max())\n","\n","    # Change channel-order and make 3 channels for matplot\n","    input_images_rgb = [x.astype(np.uint8) for x in input_images]\n","\n","    # Map each channel (i.e. class) to each color\n","    target_masks_rgb = [masks_to_colorimg(x) for x in target_masks]\n","\n","    # Left: Input image (black and white), Right: Target mask (6ch)\n","    plot_side_by_side([input_images_rgb, target_masks_rgb])\n","\n","\n","def reverse_transform(inp):\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    inp = (inp * 255).astype(np.uint8)\n","\n","    return inp\n","\n","\n","class SimDataset(Dataset):\n","    def __init__(self, count, transform=None):\n","        self.input_images, self.target_masks = generate_random_data(192, 192, count=count)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.input_images)\n","\n","    def __getitem__(self, idx):\n","        image = self.input_images[idx]\n","        mask = self.target_masks[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return [image, mask]\n","\n","\n","def get_data_loaders():\n","    # use the same transformations for train/val in this example\n","    trans = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n","    ])\n","\n","    train_set = SimDataset(100, transform = trans)\n","    val_set = SimDataset(20, transform = trans)\n","\n","    image_datasets = {\n","        'train': train_set, 'val': val_set\n","    }\n","\n","    batch_size = 25\n","\n","    dataloaders = {\n","        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n","        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n","    }\n","\n","    return dataloaders\n","\n","\n","def dice_loss(pred, target, smooth=1.):\n","    pred = pred.contiguous()\n","    target = target.contiguous()\n","\n","    intersection = (pred * target).sum(dim=2).sum(dim=2)\n","\n","    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n","\n","    return loss.mean()\n","\n","\n","def calc_loss(pred, target, metrics, bce_weight=0.5):\n","    bce = F.binary_cross_entropy_with_logits(pred, target)\n","\n","    pred = F.sigmoid(pred)\n","    dice = dice_loss(pred, target)\n","\n","    loss = bce * bce_weight + dice * (1 - bce_weight)\n","\n","    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n","    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n","    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n","\n","    return loss\n","\n","\n","def print_metrics(metrics, epoch_samples, phase):\n","    outputs = []\n","    for k in metrics.keys():\n","        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n","\n","    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n","\n","\n","def train_model(model, optimizer, scheduler, num_epochs=25):\n","    dataloaders = get_data_loaders()\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_loss = 1e10\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        since = time.time()\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                scheduler.step()\n","                for param_group in optimizer.param_groups:\n","                    print(\"LR\", param_group['lr'])\n","\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()  # Set model to evaluate mode\n","\n","            metrics = defaultdict(float)\n","            epoch_samples = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    loss = calc_loss(outputs, labels, metrics)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                epoch_samples += inputs.size(0)\n","\n","            print_metrics(metrics, epoch_samples, phase)\n","            epoch_loss = metrics['loss'] / epoch_samples\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_loss < best_loss:\n","                print(\"saving best model\")\n","                best_loss = epoch_loss\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        time_elapsed = time.time() - since\n","        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","    print('Best val loss: {:4f}'.format(best_loss))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n","\n","def run(UNet):\n","    num_class = 6\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = UNet(num_class).to(device)\n","\n","    optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n","\n","    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n","\n","    model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=60)\n","\n","    model.eval()  # Set model to the evaluation mode\n","\n","    trans = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # imagenet\n","    ])\n","    # # Create another simulation dataset for test\n","    test_dataset = SimDataset(3, transform = trans)\n","    test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n","\n","    # Get the first batch\n","    inputs, labels = next(iter(test_loader))\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","\n","    # Predict\n","    pred = model(inputs)\n","    # The loss functions include the sigmoid function.\n","    pred = F.sigmoid(pred)\n","    pred = pred.data.cpu().numpy()\n","    print(pred.shape)\n","\n","    # Change channel-order and make 3 channels for matplot\n","    input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n","\n","    # Map each channel (i.e. class) to each color\n","    target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()]\n","    pred_rgb = [masks_to_colorimg(x) for x in pred]\n","\n","    plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
